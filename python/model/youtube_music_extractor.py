# -*- coding: utf-8 -*-
"""
YouTube ìŒì•… ì¶”ì¶œ ë° ê°€ì‚¬ ìƒì„± ëª¨ë“ˆ
"""
import os
import yt_dlp
from pathlib import Path
from openai import OpenAI
import time
import re
import librosa
import numpy as np
import random

class YouTubeMusicExtractor:
    def __init__(self, openai_client: OpenAI):
        self.client = openai_client
        self.audio_dir = Path("static_audio")
        self.audio_dir.mkdir(exist_ok=True)

    def _get_random_proxy(self):
        """Webshare í”„ë¡ì‹œ í’€ì—ì„œ ëœë¤í•˜ê²Œ í”„ë¡ì‹œë¥¼ ì„ íƒí•©ë‹ˆë‹¤."""
        proxy_base = os.getenv("YT_PROXY_URL")
        if not proxy_base:
            return None

        # í”„ë¡ì‹œ ë¡œí…Œì´ì…˜: -1 ~ -40 ì ‘ë¯¸ì‚¬ ì¶”ê°€
        proxy_suffix = random.randint(1, 40)
        # http://username:password@host:port í˜•ì‹ì—ì„œ username ë’¤ì— ì ‘ë¯¸ì‚¬ ì¶”ê°€
        proxy_with_rotation = proxy_base.replace("qdsvesvs:", f"qdsvesvs-{proxy_suffix}:")
        return proxy_with_rotation

    def download_audio(self, youtube_url: str) -> str:
        """YouTubeì—ì„œ ì˜¤ë””ì˜¤ë§Œ ë‹¤ìš´ë¡œë“œ (subprocess + yt-dlp CLI, í•˜ì´ë¼ì´íŠ¸ ë°©ì‹)"""
        timestamp = int(time.time())
        audio_path = str(self.audio_dir / f'youtube_{timestamp}.mp3')

        # í”„ë¡ì‹œ ì„¤ì • (í™œì„±í™”)
        proxy = self._get_random_proxy()

        # Android User-Agentë¡œ ìš°íšŒ (ë´‡ ê°ì§€ íšŒí”¼)
        user_agents = [
            # Android Chrome
            'Mozilla/5.0 (Linux; Android 13; SM-S908B) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Mobile Safari/537.36',
            # Android Samsung Internet
            'Mozilla/5.0 (Linux; Android 13; SAMSUNG SM-S908B) AppleWebKit/537.36 (KHTML, like Gecko) SamsungBrowser/20.0 Chrome/106.0.5249.126 Mobile Safari/537.36',
            # Android Firefox
            'Mozilla/5.0 (Android 13; Mobile; rv:109.0) Gecko/120.0 Firefox/120.0',
        ]
        selected_ua = random.choice(user_agents)

        # subprocessë¡œ yt-dlp CLI ì‹¤í–‰ (í•˜ì´ë¼ì´íŠ¸ ë°©ì‹)
        command = [
            "yt-dlp",
            "--user-agent", selected_ua,
            "--extractor-args", "youtube:player_client=android",
            "--geo-bypass",
            "-x",  # ì˜¤ë””ì˜¤ë§Œ ì¶”ì¶œ
            "--audio-format", "mp3",
            "--audio-quality", "192K",
            # ê´‘ê³ /ì¸íŠ¸ë¡œ/ì•„ì›ƒíŠ¸ë¡œ ì œê±° (SponsorBlock)
            "--sponsorblock-remove", "sponsor,intro,outro,selfpromo",
            "--output", audio_path,
            youtube_url
        ]

        # í”„ë¡ì‹œ ì¶”ê°€
        if proxy:
            command.extend(["--proxy", proxy])
            # ë””ë²„ê¹…ìš©: í”„ë¡ì‹œ í˜•ì‹ í™•ì¸ (ë¹„ë°€ë²ˆí˜¸ ë§ˆìŠ¤í‚¹)
            proxy_parts = proxy.split('@')
            masked_proxy = f"{proxy_parts[0].split(':')[0]}:***@{proxy_parts[1]}" if len(proxy_parts) == 2 else "invalid format"
            print(f'ğŸ”’ í”„ë¡ì‹œ ì‚¬ìš© (CLI): {masked_proxy}')
        else:
            print(f'âš ï¸ í”„ë¡ì‹œ ì—†ìŒ - YT_PROXY_URL í™˜ê²½ë³€ìˆ˜ë¥¼ í™•ì¸í•˜ì„¸ìš”')

        print(f'ğŸ“¥ YouTube ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì¤‘ (CLI ë°©ì‹, ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ë§Œ): {youtube_url}')
        print(f'ğŸ¤– User-Agent: {selected_ua[:50]}...')

        try:
            import subprocess
            result = subprocess.run(command, check=True, capture_output=True, text=True, timeout=120)
            print(f'âœ… yt-dlp CLI ì‹¤í–‰ ì„±ê³µ')
        except subprocess.CalledProcessError as e:
            print(f'âŒ yt-dlp CLI ì‹¤í–‰ ì‹¤íŒ¨')
            print(f'stderr: {e.stderr}')
            print(f'stdout: {e.stdout}')
            raise Exception(f"YouTube ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e.stderr}")
        except subprocess.TimeoutExpired:
            raise Exception("YouTube ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ íƒ€ì„ì•„ì›ƒ (120ì´ˆ ì´ˆê³¼)")

        # ì˜¤ë””ì˜¤ íŒŒì¼ í™•ì¸
        if os.path.exists(audio_path):
            print(f'âœ… ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ (CLI, ìˆœìˆ˜ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼): {audio_path}')
            return audio_path

        raise FileNotFoundError(f"ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_path}")

    def _check_ffmpeg(self) -> bool:
        """ffmpeg ì„¤ì¹˜ ì—¬ë¶€ í™•ì¸"""
        import shutil
        return shutil.which('ffmpeg') is not None

    def get_video_id(self, youtube_url: str) -> str:
        """YouTube URLì—ì„œ video ID ì¶”ì¶œ"""
        patterns = [
            r'(?:v=|\/)([0-9A-Za-z_-]{11}).*',
            r'(?:embed\/)([0-9A-Za-z_-]{11})',
            r'^([0-9A-Za-z_-]{11})$'
        ]
        for pattern in patterns:
            match = re.search(pattern, youtube_url)
            if match:
                return match.group(1)
        raise ValueError("Invalid YouTube URL")

    def extract_lyrics_whisper(self, audio_path: str) -> dict:
        """Whisper APIë¡œ ê°€ì‚¬ ì¶”ì¶œ (í´ë°±) - íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨"""
        print(f'ğŸ¤ Whisper APIë¡œ ê°€ì‚¬ ì¶”ì¶œ ì¤‘...')

        try:
            with open(audio_path, 'rb') as audio_file:
                # verbose_json í¬ë§·ìœ¼ë¡œ íƒ€ì„ìŠ¤íƒ¬í”„ ì •ë³´ í¬í•¨
                # language íŒŒë¼ë¯¸í„° ì œê±° - ì˜ì–´+í•œêµ­ì–´ í˜¼í•© ê°€ì‚¬ ìë™ ì¸ì‹
                transcript = self.client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio_file,
                    response_format="verbose_json",
                    timestamp_granularities=["segment"]  # ì„¸ê·¸ë¨¼íŠ¸ ë ˆë²¨ íƒ€ì„ìŠ¤íƒ¬í”„
                )

            # íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨ëœ ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´ ì¶”ì¶œ
            timed_lyrics = []
            full_text = []

            if hasattr(transcript, 'segments') and transcript.segments:
                for segment in transcript.segments:
                    # segmentëŠ” ê°ì²´ì´ë¯€ë¡œ ì†ì„±ìœ¼ë¡œ ì ‘ê·¼
                    text = segment.text.strip()
                    timed_lyrics.append({
                        'text': text,
                        'start': segment.start,
                        'duration': segment.end - segment.start
                    })
                    full_text.append(text)

                print(f'âœ… Whisper ê°€ì‚¬ ì¶”ì¶œ ì™„ë£Œ (íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨, {len(timed_lyrics)}ê°œ ì„¸ê·¸ë¨¼íŠ¸)')
                return {
                    'has_timing': True,
                    'timed_lyrics': timed_lyrics,
                    'full_text': '\n'.join(full_text),
                    'method': 'whisper_with_timing'
                }
            else:
                # íƒ€ì„ìŠ¤íƒ¬í”„ ì—†ì´ í…ìŠ¤íŠ¸ë§Œ ìˆëŠ” ê²½ìš°
                print(f'âœ… Whisper ê°€ì‚¬ ì¶”ì¶œ ì™„ë£Œ (í…ìŠ¤íŠ¸ë§Œ)')
                return {
                    'has_timing': False,
                    'full_text': transcript.text if hasattr(transcript, 'text') else str(transcript),
                    'method': 'whisper'
                }

        except Exception as e:
            print(f'âš ï¸ Whisper ìƒì„¸ ì¶”ì¶œ ì‹¤íŒ¨, ê¸°ë³¸ í…ìŠ¤íŠ¸ ëª¨ë“œë¡œ ì¬ì‹œë„: {e}')
            # í´ë°±: ê¸°ë³¸ í…ìŠ¤íŠ¸ ëª¨ë“œ
            with open(audio_path, 'rb') as audio_file:
                transcript = self.client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio_file,
                    language="ko",
                    response_format="text"
                )

            print(f'âœ… Whisper ê°€ì‚¬ ì¶”ì¶œ ì™„ë£Œ (ê¸°ë³¸ ëª¨ë“œ)')
            return {
                'has_timing': False,
                'full_text': transcript,
                'method': 'whisper'
            }

    def analyze_music(self, audio_path: str) -> dict:
        """ìŒì•… íŒŒì¼ ë¶„ì„ - BPM, ë¹„íŠ¸, êµ¬ì¡° ë“±"""
        print(f'ğŸ¼ ìŒì•… ë¶„ì„ ì¤‘... (íŒŒì¼: {audio_path})')

        try:
            # íŒŒì¼ ì¡´ì¬ í™•ì¸
            if not os.path.exists(audio_path):
                raise FileNotFoundError(f"ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_path}")

            print(f'ğŸ“‚ íŒŒì¼ í™•ì¸ ì™„ë£Œ, librosaë¡œ ë¡œë”© ì¤‘...')
            # ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ (ì „ì²´ ë¡œë“œí•˜ë˜ ìµœëŒ€ 5ë¶„ìœ¼ë¡œ ì œí•œ)
            y, sr = librosa.load(audio_path, duration=300)  # ìµœëŒ€ 5ë¶„ (300ì´ˆ)
            print(f'âœ… ì˜¤ë””ì˜¤ ë¡œë“œ ì™„ë£Œ: sr={sr}, duration={len(y)/sr:.1f}ì´ˆ')

            # 1. BPM (í…œí¬) ì¶”ì¶œ
            tempo, beats = librosa.beat.beat_track(y=y, sr=sr)
            tempo = float(tempo)

            # 2. ë¹„íŠ¸ íƒ€ì„ìŠ¤íƒ¬í”„
            beat_times = librosa.frames_to_time(beats, sr=sr)

            # 3. ë¹„íŠ¸ ê°„ê²© (í‰ê· )
            beat_intervals = np.diff(beat_times)
            avg_beat_interval = float(np.mean(beat_intervals))

            # 4. ìŠ¤í™íŠ¸ëŸ´ ì¤‘ì‹¬ (ìŒìƒ‰ ë¶„ì„)
            spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]
            avg_spectral_centroid = float(np.mean(spectral_centroids))

            # 5. ì—ë„ˆì§€ (RMS)
            rms = librosa.feature.rms(y=y)[0]
            avg_energy = float(np.mean(rms))

            # 6. ìŒì•… êµ¬ì¡° ì¶”ì • (onset detection)
            onset_env = librosa.onset.onset_strength(y=y, sr=sr)
            onset_frames = librosa.onset.onset_detect(onset_envelope=onset_env, sr=sr)
            onset_times = librosa.frames_to_time(onset_frames, sr=sr)

            # 7. í…œí¬ ë¶„ë¥˜
            if tempo < 90:
                tempo_category = "ëŠë¦¼ (Slow)"
            elif tempo < 120:
                tempo_category = "ì¤‘ê°„ (Medium)"
            elif tempo < 140:
                tempo_category = "ë¹ ë¦„ (Fast)"
            else:
                tempo_category = "ë§¤ìš° ë¹ ë¦„ (Very Fast)"

            result = {
                'bpm': round(tempo, 1),
                'tempo_category': tempo_category,
                'beat_count': len(beat_times),
                'avg_beat_interval': round(avg_beat_interval, 3),
                'beat_times': beat_times.tolist(),  # ëª¨ë“  ë¹„íŠ¸ (ê°€ì‚¬ ë§¤ì¹­ìš©)
                'beat_times_sample': beat_times[:20].tolist(),  # ì²˜ìŒ 20ê°œ (ë¡œê¹…ìš©)
                'onset_count': len(onset_times),
                'onset_times': onset_times[:20].tolist(),  # ì²˜ìŒ 20ê°œ onset
                'avg_energy': round(avg_energy, 4),
                'spectral_brightness': round(avg_spectral_centroid, 2)
            }

            print(f'âœ… ìŒì•… ë¶„ì„ ì™„ë£Œ: BPM={tempo:.1f}, í…œí¬={tempo_category}')
            return result

        except Exception as e:
            import traceback
            print(f'âš ï¸ ìŒì•… ë¶„ì„ ì‹¤íŒ¨: {str(e)}')
            traceback.print_exc()
            # ê¸°ë³¸ê°’ ë°˜í™˜
            return {
                'bpm': 120,
                'tempo_category': 'ì¤‘ê°„ (Medium)',
                'beat_count': 0,
                'avg_beat_interval': 0.5,
                'beat_times': [],
                'onset_count': 0,
                'onset_times': [],
                'avg_energy': 0.1,
                'spectral_brightness': 2000
            }

    # NOTE: ì‚¬ìš©ë˜ì§€ ì•ŠìŒ - GPTì—ê²Œ ë¦¬ë“¬ ë¶„ì„ ìš”ì²­í•˜ëŠ” í•¨ìˆ˜ì˜€ìœ¼ë‚˜ ì‹¤ì œë¡œ í˜¸ì¶œë˜ëŠ” ê³³ ì—†ìŒ
    # def analyze_rhythm(self, lyrics_data: dict) -> dict:
    #     """ì›ë³¸ ê°€ì‚¬ì˜ ë¦¬ë“¬ê³¼ êµ¬ì¡° ë¶„ì„ (íƒ€ì´ë° ì •ë³´ í™œìš©)"""
    #     print(f'ğŸµ ê°€ì‚¬ ë¦¬ë“¬ ë¶„ì„ ì¤‘...')
    #
    #     original_lyrics = lyrics_data['full_text']
    #     has_timing = lyrics_data.get('has_timing', False)
    #
    #     # íƒ€ì´ë° ì •ë³´ê°€ ìˆìœ¼ë©´ ë” ì •í™•í•œ ë¶„ì„ ê°€ëŠ¥
    #     timing_info = ""
    #     if has_timing and 'timed_lyrics' in lyrics_data:
    #         timing_info = "\n\n**íƒ€ì´ë° ì •ë³´ (ì²˜ìŒ 15ê°œ ì„¸ê·¸ë¨¼íŠ¸):**\n"
    #         for i, segment in enumerate(lyrics_data['timed_lyrics'][:15]):
    #             timing_info += f"- {segment['start']:.1f}ì´ˆ: \"{segment['text']}\" (ê¸¸ì´: {segment['duration']:.1f}ì´ˆ)\n"
    #
    #     prompt = f"""
    # ë‹¤ìŒì€ ì•¼êµ¬ ì‘ì›ê°€ì˜ ê°€ì‚¬ì…ë‹ˆë‹¤. ì´ ê°€ì‚¬ì˜ ë¦¬ë“¬, êµ¬ì¡°, íŠ¹ì§•ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:
    #
    # **ê°€ì‚¬:**
    # {original_lyrics[:500]}{"..." if len(original_lyrics) > 500 else ""}
    # {timing_info}
    #
    # ë‹¤ìŒ í•­ëª©ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:
    # 1. ìŒì ˆ íŒ¨í„´ (ì˜ˆ: 3-3-4-4, ê° ë¼ì¸ì˜ ìŒì ˆ ìˆ˜)
    # 2. ë°˜ë³µ êµ¬ì¡° (í›„ë ´êµ¬, ë°˜ë³µë˜ëŠ” êµ¬ì ˆ)
    # 3. ë¦¬ë“¬ê°ê³¼ í…œí¬ (ë¹ ë¥¸/ëŠë¦°/ì¤‘ê°„, BPM ì¶”ì •)
    # 4. íŠ¹ì§•ì ì¸ í‘œí˜„ ë°©ì‹ (ë¼ì„, ìš´ìœ¨)
    # 5. í˜¸í¡ êµ¬ê°„ (ë¸Œë ˆìŠ¤ í¬ì¸íŠ¸)
    #
    # ë¶„ì„ ê²°ê³¼ë¥¼ ìƒì„¸íˆ ì‘ì„±í•´ì£¼ì„¸ìš”.
    # """
    #
    #     response = self.client.chat.completions.create(
    #         model="gpt-4o",
    #         messages=[
    #             {"role": "system", "content": "ë‹¹ì‹ ì€ ìŒì•… ë° ê°€ì‚¬ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë¦¬ë“¬, ë°•ì, ìŒì ˆ êµ¬ì¡°ë¥¼ ì •í™•íˆ ë¶„ì„í•©ë‹ˆë‹¤."},
    #             {"role": "user", "content": prompt}
    #         ],
    #         temperature=0.3
    #     )
    #
    #     analysis = response.choices[0].message.content.strip()
    #     print(f'âœ… ë¦¬ë“¬ ë¶„ì„ ì™„ë£Œ')
    #     return {
    #         "analysis": analysis,
    #         "original_lyrics": original_lyrics,
    #         "has_timing": has_timing
    #     }

    def map_lyrics_to_beats(self, lyrics_data: dict, music_analysis: dict) -> str:
        """ê°€ì‚¬ë¥¼ ë¹„íŠ¸ì— ë§ì¶° ìŒì ˆ ë°°ë¶„ íŒ¨í„´ ì¶”ì¶œ (GPTê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” í˜•íƒœ)"""
        if not lyrics_data or not lyrics_data.get('has_timing'):
            return None

        timed_lyrics = lyrics_data.get('timed_lyrics', [])
        beat_times = music_analysis.get('beat_times', [])

        if not timed_lyrics or not beat_times:
            return None

        print(f'ğŸµ ë¹„íŠ¸ë³„ ê°€ì‚¬ ë°°ë¶„ ë¶„ì„ ì¤‘...')

        beat_based_lyrics = []

        for segment in timed_lyrics:
            text = segment['text'].strip()
            if not text:
                continue

            start = segment['start']
            end = start + segment['duration']

            # ì´ ì„¸ê·¸ë¨¼íŠ¸ê°€ ëª‡ ê°œ ë¹„íŠ¸ì— ê±¸ì³ìˆëŠ”ì§€ ê³„ì‚°
            beats_in_segment = [b for b in beat_times if start <= b < end]
            num_beats = max(1, len(beats_in_segment))  # ìµœì†Œ 1ë¹„íŠ¸

            # ìŒì ˆ ìˆ˜ ê³„ì‚°
            korean_syllables = sum(1 for c in text if 'ê°€' <= c <= 'í£')
            english_words = len([w for w in text.split() if any('a' <= c.lower() <= 'z' for c in w)])

            if korean_syllables > 0 and english_words > 0:
                # í•œê¸€+ì˜ì–´ í˜¼í•©
                beat_based_lyrics.append(f'"{text}" â†’ í•œê¸€ {korean_syllables}ìŒì ˆ + ì˜ì–´ {english_words}ë‹¨ì–´ ({num_beats}ë¹„íŠ¸)')
            elif korean_syllables > 0:
                # í•œê¸€ë§Œ
                beat_based_lyrics.append(f'"{text}" â†’ {korean_syllables}ìŒì ˆ ({num_beats}ë¹„íŠ¸)')
            elif english_words > 0:
                # ì˜ì–´ë§Œ
                beat_based_lyrics.append(f'"{text}" â†’ {english_words}ë‹¨ì–´ ({num_beats}ë¹„íŠ¸)')

        if not beat_based_lyrics:
            return None

        # ì²˜ìŒ 20ê°œ ì„¸ê·¸ë¨¼íŠ¸ë§Œ (GPT í”„ë¡¬í”„íŠ¸ ê¸¸ì´ ì œí•œ)
        pattern = "\n".join(beat_based_lyrics[:20])
        print(f'âœ… ë¹„íŠ¸ë³„ ê°€ì‚¬ ë°°ë¶„ ë¶„ì„ ì™„ë£Œ ({len(beat_based_lyrics)}ê°œ ì„¸ê·¸ë¨¼íŠ¸)')

        return pattern

    # NOTE: ë¼ì¸ë³„ ìŒì ˆ ë¶„ì„ ë°©ì‹ì€ ì‹¤ì œ ë¦¬ë“¬ê³¼ ë¬´ê´€í•˜ë¯€ë¡œ ì‚¬ìš© ì•ˆ í•¨ (ì¤„ë°”ê¿ˆ ê¸°ì¤€)
    # def analyze_lyrics_structure(self, lyrics: str) -> dict:
    #     """ì›ë³¸ ê°€ì‚¬ì˜ ë¼ì¸ë³„ ìŒì ˆ êµ¬ì¡° ë¶„ì„"""
    #     lines = [line.strip() for line in lyrics.split('\n') if line.strip()]
    #
    #     structure = []
    #     for i, line in enumerate(lines[:30]):  # ì²˜ìŒ 30ì¤„ë§Œ ë¶„ì„
    #         # í•œê¸€ ìŒì ˆ ìˆ˜ ê³„ì‚°
    #         korean_syllables = sum(1 for c in line if 'ê°€' <= c <= 'í£')
    #         # ì˜ì–´ ë‹¨ì–´ ìˆ˜ ê³„ì‚°
    #         english_words = len([w for w in line.split() if any('a' <= c.lower() <= 'z' for c in w)])
    #         # ì´ ê¸€ì ìˆ˜
    #         total_chars = len(line.replace(' ', ''))
    #
    #         structure.append({
    #             'line': line,
    #             'korean_syllables': korean_syllables,
    #             'english_words': english_words,
    #             'total_chars': total_chars
    #         })
    #
    #     return structure

    def generate_cheer_lyrics(self, music_analysis: dict, player_name: str, mood: str, original_lyrics: str = None, beat_pattern: str = None) -> str:
        """ìŒì•… ë¶„ì„ ê¸°ë°˜ ì‘ì›ê°€ ê°€ì‚¬ ìƒì„± (ì›ê³¡ ë¹„íŠ¸ ë°°ë¶„ ì •ë°€ ë§¤ì¹­)"""
        print(f'âœï¸ ìƒˆë¡œìš´ ì‘ì›ê°€ ê°€ì‚¬ ìƒì„± ì¤‘...')

        # ìŒì•… ë¶„ì„ ì •ë³´
        music_info = f"""
**ìŒì•… ë¶„ì„ ê²°ê³¼:**
- BPM: {music_analysis['bpm']} ({music_analysis['tempo_category']})
- ë¹„íŠ¸ ê°„ê²©: ì•½ {music_analysis['avg_beat_interval']}ì´ˆë§ˆë‹¤ ë¹„íŠ¸
- ì—ë„ˆì§€ ë ˆë²¨: {'ë†’ìŒ' if music_analysis['avg_energy'] > 0.15 else 'ì¤‘ê°„' if music_analysis['avg_energy'] > 0.08 else 'ë‚®ìŒ'}
"""

        # ì›ë³¸ ê°€ì‚¬ ë¹„íŠ¸ ë°°ë¶„ íŒ¨í„´
        lyrics_structure = ""
        if beat_pattern:
            lyrics_structure = f"""
**ì›ë³¸ ê°€ì‚¬ ë¹„íŠ¸ë³„ ìŒì ˆ ë°°ë¶„ íŒ¨í„´:**
{beat_pattern}

âš ï¸ **ì¤‘ìš”**: Sunoê°€ ì›ê³¡ ë¦¬ë“¬ì— ë§ì¶° ë¶€ë¥´ë ¤ë©´ ìŒì ˆ ìˆ˜ê°€ ë¹„ìŠ·í•´ì•¼ í•©ë‹ˆë‹¤!
- ê° êµ¬ì ˆì˜ ìŒì ˆ ìˆ˜ë¥¼ Â±2ìŒì ˆ ì˜¤ì°¨ ë²”ìœ„ ë‚´ë¡œ ìœ ì§€
- ì˜ˆ: "11ìŒì ˆ (5ë¹„íŠ¸)" â†’ ìƒˆ ê°€ì‚¬ë„ 9~13ìŒì ˆ (5ë¹„íŠ¸ ê¸¸ì´ ìœ ì§€)
- ì˜ˆ: "3ë‹¨ì–´ (3ë¹„íŠ¸)" â†’ í•œê¸€ 6~9ìŒì ˆ (ì˜ì–´ 1ë‹¨ì–´ â‰ˆ 2-3ìŒì ˆ)
- ë¹„íŠ¸ ìˆ˜ê°€ ê°™ìœ¼ë©´ ìŒì ˆ ìˆ˜ë„ ë¹„ìŠ·í•˜ê²Œ ë§ì¶°ì•¼ Sunoê°€ ìì—°ìŠ¤ëŸ½ê²Œ ë¶€ë¦„

**ì „ì²´ ì›ë³¸ ê°€ì‚¬ (ì°¸ê³ ìš©):**
{original_lyrics if original_lyrics else ''}

"""
        elif original_lyrics:
            lyrics_structure = f"""
**ì „ì²´ ì›ë³¸ ê°€ì‚¬:**
{original_lyrics}

"""

        # NOTE: í’ˆì§ˆ ê°œì„ ì´ í•„ìš”í•˜ë©´ ì•„ë˜ ì£¼ì„ í•´ì œ
        # ì¶”ê°€ ê°€ì´ë“œ (ì°½ì˜ì„±, í”„ë¡œì„¸ìŠ¤, í’ˆì§ˆ ê¸°ì¤€):
        # - ì˜ì–´ëŠ” ì§ì—­ ê¸ˆì§€, ì˜ë¯¸ì™€ ê°ì • ì‚´ë ¤ ì°½ì˜ì  ë³€í™˜
        # - í›„ë ´êµ¬ëŠ” íŠ¹íˆ ê°•ë ¬í•˜ê³  ë°˜ë³µí•˜ê¸° ì‰½ê²Œ ì‘ì„±
        # - ê° ì„¹ì…˜ë§ˆë‹¤ ì°¨ë³„í™”: VerseëŠ” ìŠ¤í† ë¦¬í…”ë§, ChorusëŠ” ê°ì • ì ˆì •, BridgeëŠ” ì „í™˜
        # - ì¤‘ìš” êµ¬ì ˆ 2-3íšŒ ë°˜ë³µìœ¼ë¡œ ì‘ì› íš¨ê³¼ ê·¹ëŒ€í™”
        # - ë¶„ìœ„ê¸°ë³„ í‘œí˜„: ë¹ ë¦„("ë¶ˆíƒ€ì˜¬ë¼", "ì§ˆì£¼"), íŒŒì›Œ("ì²œë‘¥ê°™ì€"), ê°ë™("ê¿ˆì„ í–¥í•´")
        # - ë¦¬ë“¬ ê°•ì¡°: ê°•ì¡° ë‹¨ì–´ëŠ” ë°˜ë³µ/ëŠë‚Œí‘œ ì‚¬ìš© ("ë‹¬ë ¤ë¼! ë‹¬ë ¤ë¼!")

        prompt = f"""
{music_info}
{lyrics_structure}

**ì‘ì›ê°€ ì¡°ê±´:**
ì„ ìˆ˜: {player_name} | ë¶„ìœ„ê¸°: {mood} | BPM: {music_analysis['bpm']}

**í•µì‹¬ ê·œì¹™:**
1. ì›ë³¸ ë¹„íŠ¸ë³„ ìŒì ˆ ìˆ˜ ë¹„ìŠ·í•˜ê²Œ ìœ ì§€ (ìœ„ íŒ¨í„´ì˜ ê° êµ¬ì ˆ ìŒì ˆ ìˆ˜ Â±2 ì˜¤ì°¨)
   - SunoëŠ” ì›ê³¡ ë¹„íŠ¸ì— ê°€ì‚¬ë¥¼ ë§ì¶° ë¶€ë¥´ë¯€ë¡œ ìŒì ˆ ìˆ˜ê°€ ì¤‘ìš”!
   - "11ìŒì ˆ (5ë¹„íŠ¸)" êµ¬ì ˆ â†’ ìƒˆ ê°€ì‚¬ 9~13ìŒì ˆë¡œ ì‘ì„±
2. ì˜ì–´ â†’ í•œê¸€ ë³€í™˜: 1ë‹¨ì–´ â‰ˆ 2-3ìŒì ˆ, ì§ì—­ ê¸ˆì§€í•˜ê³  ì°½ì˜ì  ë³€í™˜
   ì˜ˆ: "Go Tigers"â†’"ë‹¬ë ¤ë¼ ìš°ë¦¬ íŒ€" (ë‹¨ìˆœ "ê°€ì íƒ€ì´ê±°ì¦ˆ" ê¸ˆì§€)
       "Let's fight"â†’"ìŠ¹ë¦¬ë¥¼ í–¥í•´" (ë‹¨ìˆœ "ì‹¸ìš°ì" ê¸ˆì§€)
3. ì„ ìˆ˜ ì´ë¦„ì€ í›„ë ´êµ¬ ìœ„ì£¼ ì‚¬ìš© (ë§¤ ì¤„ ë°˜ë³µ ê¸ˆì§€), í˜¸ì¹­ í˜¼ìš© ("ì˜ì›…", "ë³„", "ì±”í”¼ì–¸")
4. ë³µí•©ì–´ ë„ì–´ì“°ê¸°: "í™ˆëŸ°ì™•"â†’"í™ˆëŸ° ì™•", "í™”ì´íŒ…"â†’"í™”ì´ íŒ…"
5. ë°œìŒ ì‰¬ìš´ ë‹¨ì–´ ìš°ì„ , ë°›ì¹¨ ì—°ì† ì§€ì–‘: "ì•ŠëŠ”"â†’"ì•„ë‹ˆì•¼"

**í‘œí˜„ ê°€ì´ë“œ:**
- ì•¼êµ¬ íƒ€ì ìš©ì–´: í™ˆëŸ°, ì•ˆíƒ€, ë“ì , í´ëŸ¬ì¹˜, íƒ€ê²©, ì¥íƒ€ (íˆ¬ìˆ˜ ìš©ì–´ ê¸ˆì§€: ì‚¼ì§„, ë§ˆìš´ë“œ ë“±)
- ê°ì •: ì—´ì •, í™˜í˜¸, ê°ë™, ì „ìœ¨ | ê²½ê¸°ì¥: íŒ¬ë“¤, í•¨ì„±, í•¨ê»˜
- ë“œë¼ë§ˆí‹± í‘œí˜„: "ë‹¬ë ¤ë¼ ë°”ëŒì²˜ëŸ¼", "í„°ëœ¨ë ¤ë¼ í™ˆëŸ°"
- ë¼ì„ í™œìš©: "ìŠ¹ë¦¬/ê¸°ì¨ì´", "ë¹›ë‚˜/í”¼ì–´ë‚˜"

**ì¶œë ¥ í˜•ì‹:**
[Verse 1]
ê°€ì‚¬...

[Chorus]
í›„ë ´êµ¬...

[Verse 2]
ê°€ì‚¬...

[Chorus]
í›„ë ´êµ¬...

[Bridge]
ë¸Œë¦¿ì§€...

[Chorus]
í›„ë ´êµ¬...

- ì„¹ì…˜ íƒœê·¸([Verse], [Chorus], [Bridge]) ëŒ€ê´„í˜¸ í•„ìˆ˜
- {"ì›ë³¸ ì„¹ì…˜ êµ¬ì¡° ë™ì¼í•˜ê²Œ ìœ ì§€" if original_lyrics else "ìì—°ìŠ¤ëŸ¬ìš´ ì „ê°œ"}
- ë²ˆí˜¸/ë”°ì˜´í‘œ ì‚¬ìš© ê¸ˆì§€, ê°€ì‚¬ë§Œ ì¶œë ¥
"""

        response = self.client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ KBO ì•¼êµ¬ ì‘ì›ê°€ ì „ë¬¸ ì‘ì‚¬ê°€ì…ë‹ˆë‹¤. ì›ê³¡ ë¦¬ë“¬ê³¼ ìŒì ˆ íŒ¨í„´ì„ ì •í™•íˆ ë¶„ì„í•˜ì—¬ ê°ë™ì ì´ê³  ì¤‘ë…ì„± ìˆëŠ” í•œê¸€ ì‘ì›ê°€ë¥¼ ì°½ì‘í•©ë‹ˆë‹¤. ë°œìŒì´ ëª…í™•í•˜ê³  ê²½ê¸°ì¥ ì „ì²´ê°€ í•¨ê»˜ ë¶€ë¥¼ ìˆ˜ ìˆëŠ” ê°•ë ¬í•œ ê°€ì‚¬ë¥¼ ë§Œë“œì„¸ìš”."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7  # ë” ì°½ì˜ì ì¸ í‘œí˜„ì„ ìœ„í•´ ë†’ì„
        )

        lyrics = response.choices[0].message.content.strip()
        print(f'âœ… ì‘ì›ê°€ ê°€ì‚¬ ìƒì„± ì™„ë£Œ')
        return lyrics

    def cleanup(self, audio_path: str):
        """ì„ì‹œ íŒŒì¼ ì‚­ì œ"""
        try:
            if os.path.exists(audio_path):
                os.remove(audio_path)
                print(f'ğŸ—‘ï¸ ì„ì‹œ íŒŒì¼ ì‚­ì œ: {audio_path}')
        except Exception as e:
            print(f'âš ï¸ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}')
